# Literature
# The One-way Error Component Regression Model

## INTRODUCTION

A panel data regression differs from a regular time-series or cross-section regression in that it
has a double subscript on its variables, i.e.


$$  y_{it}= \alpha + X_{it}^{'} \beta + u_{it}                      $$
$$ i=1, ... , N  ; t=1, ... ,T  $$
(2.1)


with $$ i $$  denoting households, individuals, firms, countries, etc. and t denoting time. The i subscript, therefore, denotes the cross-section dimension whereas t denotes the time-series dimension. $$ \alpha  $$ is a scalar, $$ \beta $$ is $$ K × 1 $$ and Xi t is the $$ it_{th} $$ observation on K explanatory variables.
Most of the panel data applications utilize a one-way error component model for the disturbances, with

$$ u_{it}= \mu_i +  v_{it}      $$
(2.2)

where μi denotes the unobservable individual-specific effect and νi t denotes the remainder disturbance. For example, in an earnings equation in labor economics, yi t will measure earnings of the head of the household, whereas $$ X_{it} $$ may contain a set of variables like experience, education, union membership, sex, race, etc. Note that μi is time-invariant and it accounts for any individual-specific effect that is not included in the regression. In this case we could think of it as the individual’s unobserved ability. The remainder disturbance $$ v_{it} $$ varies with individuals and time and can be thought of as the usual disturbance in the regression. Alternatively, for a production function utilizing data on firms across time, $$ y_{it} $$ will measure output and $$ X_{it} $$ will measure inputs. The unobservable firm-specific effects will be captured by the $$ \mu_i $$
and we can think of these as the unobservable entrepreneurial or managerial skills of the firm’s executives. Early applications of error components in economics include Kuh (1959) on investment, Mundlak (1961) and Hoch (1962) on production functions and Balestra and Nerlove (1966) on demand for natural gas. In vector form (2.1) can be written as

$$ y= \alpha i_{NT} + X \beta + u = Z \delta + u      $$    (2.3)

$$ y= \alpha i_{NT} + X \beta + u = Z \delta + u      $$    (2.3)

where $$ y $$ is $$ NT × 1 $$, $$ X $$ is $$ NT × K $$, $$ Z = [ι_{NT} , X] $$,
$$ \delta^{'} = (α^{'},\beta^{'}) $$ and $$ι_NT$$ is a vector of ones of
dimension NT. Also, (2.2) can be written as

$$ u=Z_\mu \mu +v  $$ (2.4)

$$  y_{it} = \alpha + X_{it}^{'} + U_{it}   $$ , $ i=1,...,N ; t=1,...,T   $
with i denoting households, individuals, firms, countries, etc. and t denoting time. The i subscript, therefore, denotes the cross-section dimension whereas t denotes the time-series dimension. $ \alpha $ is a scalar, $ \beta $ is $ K × 1 $ and  $X_{it} $is the $ it^{th} $ observation on K explanatory variables.
disturbances, with it
$$ u_{it}=u_i  + v_{it}     $$

where μi denotes the unobservable individual-specific effect and $ν{it}$  denotes the remainder disturbance. For example, in an earnings equation in labor economics, $y_{it}$ will measure earnings of the head of the household, whereas Xi t may contain a set of variables like experience, education, union membership, sex, race, etc. Note that μi is time-invariant and it accounts for any individual-specific effect that is not included in the regression. In this case we could think of it as the individual’s unobserved ability. The remainder disturbance $ ν{it} $ varies with individuals
and time and can be thought of as the usual disturbance in the regression. Alternatively, for a production function utilizing data on firms across time, $ y_{it} $ will measure output and $ X_{it} $ will measure inputs. The unobservable firm-specific effects will be captured by the $ \mu_i $ and we can think of these as the unobservable entrepreneurial or managerial skills of the firm’s executives. Early applications of error components in economics include Kuh (1959) on investment, Mundlak (1961) and Hoch (1962) on production functions and Balestra and Nerlove (1966) on demand for natural gas. In vector form (2.1) can be written as 

$$ y= \alpha i_{NT}  + X\beta +u = Z\delta + u $$

where $y$  is $ NT × 1$ , X is $NT × K$ , $ Z = [i_{NT} , X] $ , $ \delta^{'}=(\alpha^{'},\beta^{'}) $  and $i_{NT}$ is a vector of ones of dimension $NT$ . Also, (2.2) can be written as  

$$ u=Z_\mu \mu  + v$$ 
(2.4)

where $ u^{'} = (u_{11}, . . . , u_{1T} , u_{21}, . . . , u_{2T}, . . . , u_{N1}, . . . , u_{NT} ) $ with the observations stacked
such that the slower index is over individuals and the faster index is over time.$ Z_\mu = IN \otimes ιT $
where IN is an identity matrix of dimension N, ιT is a vector of ones of dimension  T and $ \otimes $ denotes Kronecker product. $ Z_\mu $ is a selector matrix of ones and zeros, or simply the matrix of individual dummies that one may include in the regression to estimate theμi if they are assumed to
be fixed parameters. $ \mu^{'} = (\mu_1, . . . , \mu_N )$ and $ν^{'} = (ν11, . . . , ν_{1T} , . . . , ν_{N1}, . . . , ν_{NT} )$. Note that

